---
title: Predicting Customer Satisfaction
author: Ευάγγελος Δημητρίου
date: February 12, 2025
format:
  docx:
    toc: true
    toc-depth: 3
    toc-title: Περιεχόμενα
jupyter: python3
email: evdimitriou@uth.gr
id: 1369
affiliation:
  name: Πανεπιστήμιο Θεσσαλίας
  location: Λαμία, Φθιώτιδα
  url: https://dib.uth.gr/
---

Στα πλαίσια του μαθήματος "Εξόρυξη και Ανάλυση Δεδομένων Μεγάλου Όγκου", ανέλαβα την εργασία κατηγοριοποίησης με θέμα "Airline Passenger Satisfaction", από τον αξιότιμο επιβλέποντα καθηγητή κ. Σωτήριο Τασουλή. Η παρούσα αναφορά θα δοκιμάσει την εφαρμογή μοντέλων πρόβλεψης σε μια προσπάθεια εύρεσης λύσης σε ένα πρόβλημα που απασχολεί τις περισσότερες εταιρείες παροχής υπηρεσιών, την *Ικανοποίηση Πελατών*. 

## **Δεδομένα** 

`Αρχεία: train.csv, test.csv`. Το παρών σύνολο δεδομένων αποτείται από 2 αρχεία, τα οποία υποδεικνύουν και τα ειδικά σύνολα *εκπαίδευσης* και *δοκιμής*. Στη συνέχεια, τα σύνολα θα μεταφραστούν στην γλώσσα προγραμματισμού *`Python`*, στη μορφή του *`Pandas DataFrame object`*. Μετά την ***Διερευνητική Ανάλυση* (Explanatory Data Analysis)**, τον ***καθαρισμό* (Cleaning)** και την ***μοντελοποίηση* (Modeling)** των δεδομένων, τα ίδια σύνολα θα υποβληθούν στον υπολογισμό των ***συντελεστών συσχετίσεων* (Correlation Coefficients)** με αποτέλεσμα να γίνουν εμφανείς οι ισχυροί και οι αδύναμοι δεσμοί μεταξύ της ***εξαρτημένης μεταβλητής* (Response Variable)** και των διαστάσεων της ***ανεξάρτητης μεταβλητής* (Indepedant Variable)**. Η αναγνώριση και ταυτοποίηση των δεσμών αυτών, θα είναι ο πιο καθοριστικός παράγοντας της ***αξιολόγησης* (Evaluation)** των ***μοντέλων μηχανικής μάθησης και πρόβλεψης* (Predictive Machine Learning Models)**. Τα *μοντέλα πρόβλεψης* θα εκπαιδευτούν και θα δοκιμαστούν στα αντίστοιχα, προεπεξαργασμένα πλέον, δεδομένα εκπαίδευσης και δοκιμής των αρχικών δεδομένων που ανακτήθηκαν διαδικτυακά από: 
[kaggle.com](https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction)
  

### **Περιεχόμενα:**
Το περιεχόμενο των δεδομένων είναι το αποτέλεσμα μίας εταιρικής έρευνας από τμήματα της εταιρίας όπως Εξυπηρέτηση Πελατών, Επιστημόνων Αναλυτών και Μηχανικών Δεδομένων, Marketing. Η έρευνα αποτελούταν από δείγμα με 129.880 πελάτες της εταιρίας, οι οποίοι υποβλήθηκαν σε δημογραφικές ερωτήσεις και ερωτήσεις κλίμακας Likert ("Likert scale questions"). Παρακάτω αναγράφονται οι στήλες-μεταβλητές, οι οποίες χρησιμοποιήθηκαν από τον επισυναπτόμενο κώδικα.

- **Gender**: Το φύλο των επιβατών (Γυναίκα, Άντρας)  

- **Customer Type**: Ο τύπος του πελάτη (Συχνός πελάτης, Μη συχνός πελάτης)  

- **Age**: Η πραγματική ηλικία των επιβατών  

- **Type of Travel**: Ο σκοπός της πτήσης των επιβατών (Προσωπικό Ταξίδι, Επαγγελματικό Ταξίδι)  

- **Class**: Η κατηγορία ταξιδιού στο αεροπλάνο των επιβατών (Επαγγελματική, Οικονομική, Οικονομική Plus)  

- **Flight distance**: Η απόσταση της πτήσης αυτής  

- **Inflight wifi service**: Επίπεδο ικανοποίησης από την υπηρεσία wifi εν πτήσει (0: Δεν εφαρμόζεται; 1-5)  

- **Departure/Arrival time convenient**: Επίπεδο ικανοποίησης από την καταλληλότητα της ώρας αναχώρησης/άφιξης  

- **Ease of Online booking**: Επίπεδο ικανοποίησης από την ευχέρεια της online κράτησης  

- **Gate location**: Επίπεδο ικανοποίησης από την τοποθεσία της πύλης  

- **Food and drink**: Επίπεδο ικανοποίησης από το φαγητό και το ποτό  

- **Online boarding**: Επίπεδο ικανοποίησης από την online επιβίβαση  

- **Seat comfort**: Επίπεδο ικανοποίησης από την άνεση της θέσης  

- **Inflight entertainment**: Επίπεδο ικανοποίησης από την ψυχαγωγία εν πτήσει  

- **On-board service**: Επίπεδο ικανοποίησης από την υπηρεσία εν πτήσει  

- **Leg room service**: Επίπεδο ικανοποίησης από την υπηρεσία χώρου για τα πόδια  

- **Baggage handling**: Επίπεδο ικανοποίησης από τη διαχείριση των αποσκευών  

- **Check-in service**: Επίπεδο ικανοποίησης από την υπηρεσία check-in  

- **Inflight service**: Επίπεδο ικανοποίησης από την υπηρεσία εν πτήσει  

- **Cleanliness**: Επίπεδο ικανοποίησης από την καθαριότητα  

- **Departure Delay in Minutes**: Καθυστέρηση αναχώρησης σε λεπτά  

- **Arrival Delay in Minutes**: Καθυστέρηση άφιξης σε λεπτά  

- **Satisfaction**: Επίπεδο ικανοποίησης αεροπορικής εταιρείας (Ικανοποιημένος, ουδέτερος ή δυσαρεστημένος)


Παρακάτω, εισάγουμε τις απαραίτητες βιβλιοθήκες της Python, που θα βοηθήσουν την ανάλυσή μας.

```{python}
# Εισαγωγή Απαραίτητων Βιβλιοθηκών
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA, KernelPCA
```

### **Κατανόηση Δεδομένων**

  - **Αρχική επισκόπηση:**

    Εξετάζουμε τα αρχεία train.csv και test.csv:
    
    - **Μεθοδολογία:**
    
      + Πόσες γραμμές και στήλες έχουν;

      + Ποια είναι τα χαρακτηριστικά (features) τους;

      + Υπάρχουν ετικέτες (labels) για κατηγοριοποίηση στο αρχείο train.csv;

      + Τύποι δεδομένων (αριθμητικά, κατηγορικά, ημερομηνίες κ.λπ.).

      + Ανάλυση βασικών στατιστικών (μέση τιμή, διασπορά κ.λπ.) για αριθμητικά δεδομένα.

      + Εξετάζουμε πιθανές ελλιπείς τιμές.    
Εντολές Python:

```{python}
# Ανάγνωση δεδομένων εκπαίδευσης από αρχείο .csv
train_data = pd.read_csv('train.csv')


# Βασική Ανάλυση
print("\n~~Trian Head~~\n")
print(train_data.head())

print("\n~~Train info~~\n")
print(train_data.info())

print("\n~~Train describe~~\n")
print(train_data.describe())

# Nan τιμές
print("\n~~Train isnull.sum~~\n")
print(train_data.isnull().sum())
```

```{python}
# Ανάγνωση δεδομένων δοκιμής από αρχείο .csv
test_data = pd.read_csv('test.csv')



# Βασική Ανάλυση
print("\n~~Test Head~~\n")
print(test_data.head())

print("\n~~Test info~~\n")
print(test_data.info())

print("\n~~Test describe~~\n")
print(test_data.describe())

# Nan τιμές
print("\n~~Test isnull.sum~~\n")
print(test_data.isnull().sum())
```

```{python}
# Στατιστικά κατηγορικών μεταβλητών
print("\n~~Gender.value_counts~~\n")
print(train_data['Gender'].value_counts())

print("\n~~satisfaction.value_counts~~\n")
print(train_data['satisfaction'].value_counts())

print("\n~~Customer Type.value_counts~~\n")
print(train_data['Customer Type'].value_counts())

print("\n~~Class.value_counts~~\n")
print(train_data['Class'].value_counts())

print("\n~~Type of Travel.value_counts~~\n")
print(train_data['Type of Travel'].value_counts())
```

#### **Συνεπείς μορφές δεδομένων**
Η συνεπής ποιότητα και δομή των δεδομένων εισόδου είναι κρίσιμη για ένα μοντέλο πρόβλεψης, επειδή:

Σε κάποιες κατηγορικές μεταβλητές των dataset, παρατηρούμε μια ασυνταξία στα κεφαλαία και πεζά strings. Για αυτό, θα πραγματοποιήσουμε μετατροπές αυτών ώστε να επιτύχουμε συνέπεια και συνέχεια στα δεδομένα μας.

```{python}
# Μετατροπή της μεταβλητής "Customer Type"
train_data['Customer Type'] = train_data['Customer Type'].str.lower()
test_data['Customer Type'] = test_data['Customer Type'].str.lower()

# Μετατροπή της μεταβλητής "Type of Travel"
train_data['Type of Travel'] = train_data['Type of Travel'].str.lower()
test_data['Type of Travel'] = test_data['Type of Travel'].str.lower()
```

#### **Καθαρισμός και Μετασχηματισμός των Dataset**
Βάσει των δεδομένων εκπαίδευσης που παρουσιάστηκαν παραπάνω, υπάρχουν αρκετά βήματα που πρέπει να ακολουθήσουμε για να προετοιμάσουμε τα δεδομένα για χρήση στα μοντέλα μας. Υπάρχουν αρκετές κατηγορικές μεταβλητές που χρειάζεται να κωδικοποιηθούν, συμπεριλαμβανομένης της μεταβλητής-στόχου μας, *`"Satisfaction"`*. Επιπλέον, υπάρχουν κάποιες στήλες που είναι περιττές, όπως οι *`"Unnamed: 0"`* και *`"id"`*. Μπορούμε να τις αφαιρέσουμε. Οι παρακάτω συναρτήσεις θα χρησιμοποιηθούν για την προετοιμασία του συνόλου δεδομένων.

```{python}
# Συνάρτηση μετασχηματισμού της κατηγορικής μεταβλητής "satisfaction"
def transform_satisfaction(x):
    if x == 'satisfied':
        return 1
    elif x == 'neutral or dissatisfied':
        return 0
    else:
        return -1

#------------------------------------------------------------------------

# Συνάρτηση μετασχηματισμού της κατηγορικής μεταβλητής "Gender"
def transform_gender(x):
    if x == 'Female':
        return 1
    elif x == 'Male':
        return 0
    else:
        return -1

#------------------------------------------------------------------------

# Συνάρτηση μετασχηματισμού της κατηγορικής μεταβλητής "Customer Type"
def transform_customer_type(x):
    if x == 'loyal customer':
        return 1
    elif x == 'disloyal customer':
        return 0
    else:
        return -1
    
#------------------------------------------------------------------------

# Συνάρτηση μετασχηματισμού της κατηγορικής μεταβλητής "Class"
def transform_class(x):
    if x == 'Business':
        return 2
    elif x == 'Eco Plus':
        return 1
    elif x == 'Eco':
        return 0
    else:
        return -1

#------------------------------------------------------------------------

# Συνάρτηση μετασχηματισμού της κατηγορικής μεταβλητής "Type of Travel"
def transform_type_of_travel(x):
    if x == 'business travel':
        return 1
    elif x == 'personal travel':
        return 0
    else:
        return -1

#------------------------------------------------------------------------
```

#### **Επεξήγηση των συναρτήσεων**
**Συνοχή στις εξόδους**:
   - Όλες οι συναρτήσεις επιστρέφουν ακέραιες τιμές, κάνοντας το σύνολο δεδομένων πιο συμβατό με τους αλγορίθμους μηχανικής μάθησης.


#### **Εφαρμογή των συναρτήσεων**
Οι συναρτήσεις μας είναι έτοιμες να μετασχηματίσουν τις μεταβλητές μας. H μέθοδος *`.apply()`*, η οποία δέχεται ως όρισμα μια οποιαδήποτε συνάρτηση, εφαρμόζει την συνάρτηση σε κάποια **`Pandas Series`**.
Όμως, δεν πρέπει να ξεχνάμε και τους υπόλοιπους μετασχηματισμούς:
1. Η μέθοδος .drop() δέχεται ως όρισμα, εδώ σε μορφή λίστας, τα ονόματα των μεταβλητών που είναι περιττές, όπως περιγράψαμε παραπάνω: *`"Unnamed: 0", "id"`* και τις διαγράφει από το DataFrame. Το argument *`axis=1`* μας υποδεικνύει τον άξονα στον οποίο θα πραγματοποιηθούν οι διαγραφές, η τιμή *`1`* υποδηλώνει ότι ο άξονας αυτός είναι ο άξονας των στηλών στο DataFrame.
2. Παραπάνω, παρατηρήσαμε ελλείψεις τιμών στην μεταβλητή "Arrival Delay in Minutes".    
    Θα προτιμήσουμε την αντικατάσταση των **null** τιμών με συγκεκριμένη τιμή μέσω της μεθόδου *`.fillna()`*. Μάλιστα, αντί να αποδώσουμε αυθαίρετα μία ακέραια τιμή στις εκλείποντες τιμές, μέσα στην *.fillna()* θα υπολογίσουμε την μέση τιμή της μεταβλητής (median value), μέσω της μεθόδου *`.median()`*.

Χρησιμοποιώντας την λογική των συναρτήσεων, μπορούμε να μετασχηματίσουμε και τα δεδομένα εκπαίδευσης και τα δεδομένα εκτίμησης ταυτόχρονα:

```{python}
# Προεπεξεργασία των δεδομένων χρησιμοποιώντας την συνάρτηση preprocess_data
def preprocess_data(df):
    df = df.drop(['Unnamed: 0', 'id'], axis=1) # Αφαίρεση περιττών στηλών
    df['Gender'] = df['Gender'].apply(transform_gender) # Μετατροπή κατηγορικών μεταβλητών
    df['Customer Type'] = df['Customer Type'].apply(transform_customer_type) # Μετατροπή κατηγορικών μεταβλητών
    df['Type of Travel'] = df['Type of Travel'].apply(transform_type_of_travel) # Μετατροπή κατηγορικών μεταβλητών
    df['Class'] = df['Class'].apply(transform_class) # Μετατροπή κατηγορικών μεταβλητών
    df['satisfaction'] = df['satisfaction'].apply(transform_satisfaction) # Μετατροπή της μεταβλητής στόχου
    df['Arrival Delay in Minutes'] = df['Arrival Delay in Minutes'].fillna(df['Arrival Delay in Minutes'].median()) # Διαχείριση ελλιπών τιμών
    
    return df # Επιστροφή του επεξεργασμένου DataFrame
```

#### **Η συνάρτηση *`preprocess_data(df)`*:**
Ο παραπάνω κώδικας υλοποιεί τη συνάρτηση *`preprocess_data(df)`*, η οποία πραγματοποιεί προεπεξεργασία του DataFrame με τις εξής πράξεις:
1. Αφαιρεί τις αχρείαστες στήλες.
2. Μετατρέπει κατηγορικές μεταβλητές σε αριθμητική μορφή.
3. Κωδικοποιεί τη μεταβλητή στόχο.
4. Αντικαθιστά ελλιπείς τιμές.
5. Επιστρέφει ένα καθαρό και επεξεργασμένο DataFrame έτοιμο για εκπαίδευση μοντέλων.

```{python}
# Εφαρμογή της συνάρτησης preprocess_data και στα δύο σύνολα δεδομένων
train_processed = preprocess_data(train_data) # Αυτή η γραμμή εφαρμόζει τη συνάρτηση `preprocess_data()` στο σύνολο δεδομένων εκπαίδευσης `train`.
test_processed = preprocess_data(test_data) # Αυτή η γραμμή εκτελεί την ίδια διαδικασία για τα δεδομένα εκτίμησης (`test`).
```

#### **Σκοπός της διαδικασίας:**
- **Προετοιμασία των δεδομένων**: Η συνάρτηση `preprocess_data()` εξασφαλίζει ότι τόσο τα δεδομένα εκπαίδευσης όσο και τα δεδομένα εκτίμησης είναι σε μια κατάλληλη μορφή για να χρησιμοποιηθούν από τους αλγόριθμους μηχανικής μάθησης.

- **Ομοιομορφία**: Οι κατηγορικές μεταβλητές μετατρέπονται σε αριθμητικά χαρακτηριστικά, και οι ελλιπείς τιμές αντιμετωπίζονται, διασφαλίζοντας ότι οι αλγόριθμοι μηχανικής μάθησης μπορούν να τα διαχειριστούν χωρίς προβλήματα.

#### **Σημαντικά σημεία:**
- **Εκπαίδευση και Εκτίμηση**: Είναι σημαντικό ότι ο ίδιος ακριβώς μετασχηματισμός εφαρμόζεται και στα δεδομένα εκτίμησης (`test`), έτσι ώστε το μοντέλο να αντιμετωπίσει τα δεδομένα με τον ίδιο τρόπο όπως στα δεδομένα εκπαίδευσης.

- **Αναγκαία Προετοιμασία**: Ο μετασχηματισμός των δεδομένων σε αριθμητική μορφή είναι κρίσιμος για τη σωστή εκπαίδευση και αξιολόγηση του μοντέλου.

## **Σχεδιασμός Εξόρυξης Δεδομένων και Πρόβλεψης**

### **Εξόρυξη Δεδομένων (Data Mining)**

- Ερωτήματα που μπορούμε να απαντήσουμε:

    - Ποια χαρακτηριστικά έχουν τη μεγαλύτερη επίδραση σε κάποιο αποτέλεσμα;

    - Υπάρχουν ομάδες δεδομένων (clusters) που μοιράζονται παρόμοια χαρακτηριστικά;
    
#### **Μεθοδολογία:**

1. Ανάλυση Συσχέτισης: 
    - Υπολογίζουμε τη συσχέτιση μεταξύ χαρακτηριστικών. Με την χρήση της μεθόδου *`.corr()`*. Θα δοκιμάσουμε 2 συντελεστές συσχέτισης: 
        - του Pearson ( θέτοντας το argumnent *`method='pearson'`* )
        - του Spearman ( θέτοντας το argumnent *`method='spearman'`* )

2. Οπτικοποίηση Δεδομένων: 
    - Χρησιμοποιώντας διαγράμματα για ανίχνευση σχέσεων.

#### **Ανισόρροπα δεδομένα**
Ας εξετάσουμε πρώτα, αν οι κλάσεις της μεταβλητής-στόχου "satisfaction" των δεδομένων εκπαίδευσης είναι καλά ή όχι ισορροπημένες. Πολύ απλά, με ένα *`sns.barplot()`* μπορούμε να απεικονίσουμε τα πραγματικά νούμερα των 2 κλάσεων και να δούμε πόσα δείγματα υπάρχουν σε κάθε κατηγορία. Τέλος, ένα *`plt.pie()`* παρέχει μια καθαρή εικόνα της αναλογίας των κατηγοριών.

```{python}
# Υπολογισμός συχνοτήτων για τη μεταβλητή-στόχο "satisfaction"
class_counts = train_processed['satisfaction'].value_counts()
class_counts.index = class_counts.index.map({1: 'Satisfied', 0: 'Unsatisfied'})

# Εμφάνιση απόλυτων και ποσοστιαίων τιμών
print("Απόλυτες συχνότητες κάθε κλάσης:")
print(class_counts)

print("\nΠοσοστά κάθε κλάσης:")
print(round((class_counts / len(train_processed) * 100), 2))

# Δημιουργία του figure και των subplots
fig, axes = plt.subplots(1, 2, figsize=(16, 8))

# Bar plot για απόλυτες συχνότητες
sns.barplot(ax=axes[0], x=class_counts.index, y=class_counts.values, palette="tab10", legend=True)
axes[0].set_title("Απόλυτες Συχνότητες Κλάσεων", fontsize=16)
axes[0].set_xlabel("Κλάσεις", fontsize=12)
axes[0].set_ylabel("Συχνότητα", fontsize=12)

# Pie chart για ποσοστά
axes[1].pie(class_counts.values, labels=class_counts.index, autopct='%1.2f%%', startangle=140, colors=sns.color_palette("tab10"))
axes[1].set_title("Ποσοστά Κλάσεων", fontsize=16)

# Ρύθμιση κενών μεταξύ των plots
plt.tight_layout()
plt.show()
```

##### **Συμπέρασμα:**
Από τα γραφήματα, προκύπτει ότι η μεταβλητή-στόχος "satisfaction" είναι αρκετά ισορροπημένη και δεν χρειάζεται η εφαρμογή περεταίρω δειγματοληψίας ή αλλων τεχνικών.

```{python}
# Υπολογισμός συσχετίσεων
# Συντελεστής συσχέτισης Pearson
corr_pearson = train_processed.corr(method='pearson')
# Συντελεστής συσχέτισης Spearman
corr_spearman = train_processed.corr(method='spearman')

# ΓΡΑΦΗΜΑΤΑ:
# Δημιουργία μάσκας για το πάνω τριγωνικό τμήμα
# Η μάσκα κρύβει το πάνω τριγωνικό τμήμα του πίνακα για αποδοτικότερη οπτικοποίηση. 
mask = np.triu(np.ones_like(corr_spearman, dtype=bool))

# Δημιουργία υπογραφημάτων (subplots)
fig, axes = plt.subplots(1, 2, figsize=(25, 10), sharey=True)  # 1 γραμμή, 2 στήλες


# Heatmap για Spearman
sns.heatmap(corr_spearman, annot=True, annot_kws={"size": 10, "color": "black"}, mask=mask, cmap='PRGn', center=0,
            square=True, linewidths=.8, ax=axes[0], fmt=".2f")
axes[0].set_title("Spearman Correlation Coefficient", fontsize=14)

# Heatmap για Pearson
sns.heatmap(corr_pearson, annot=True, annot_kws={"size": 10, "color": "black"}, mask=mask, cmap='PuBu', center=0,
            square=True, linewidths=.8, ax=axes[1], fmt=".2f")
axes[1].set_title("Pearson Correlation Coefficient", fontsize=14)

# Εμφάνιση γραφήματος
plt.tight_layout()
plt.show()
```

Ο παραπάνω κώδικας εφαρμόζει την μεθοδολογία και εκτελεί:

#### **Υπολογισμός των Συσχετίσεων:**

Υπολογίζονται ξεχωριστά οι πίνακες συσχετίσεων για **Spearman** (*`corr_spearman`*) και **Pearson** (*`corr_pearson`*).

Ο κώδικας παράγει δύο heatmaps, το ένα για τον Spearman συντελεστή συσχέτισης και το άλλο για τον Pearson, τοποθετημένα δίπλα-δίπλα.

### **Κατανόηση του προβλήματος και εισαγωγή των μοντέλων πρόβλεψης**

Η πρόβλεψη της ικανοποίησης πελατών είναι ένα πρόβλημα κατηγοριοποίησης όπου η μεταβλητή-στόχος είναι ***διωνυμική***  (*binary*), π.χ. ικανοποιημένος ή μη ικανοποιημένος. Αυτό σημαίνει ότι υπάρχουν δύο δυνατές τιμές για την έκβαση: Είτε *ο πελάτης έμεινε ευχαριστημένος*, είτε *δεν έμεινε ευχαριστημένος*. Στην αναφορά αυτή, θα χρησιμοποιηθούν 2 μοντέλα πρόβλεψης από 2 αλγόριθμους:

- **1. Gaussian Naive Bayes (GNB)**
- **2. Λογιστική Παλινδρόμηση - Logistic Regression**

### **Διαχωρισμός των μεταβλητών σε στόχος και χαρακτηριστικά**

```{python}
# Διαχωρισμός των μεταβλητών σε στόχος και χαρακτηριστικά
# **X_train** και **X_test**: Περιέχουν τα χαρακτηριστικά των δεδομένων, δηλαδή όλες τις στήλες εκτός από τη στήλη `'satisfaction'`.
# **y_train** και **y_test**: Περιέχουν τις ετικέτες στόχου (την "ικανοποίηση"), δηλαδή την στήλη `'satisfaction'`.
X_train = train_processed.drop('satisfaction', axis=1) 
y_train = train_processed['satisfaction']

X_test = test_processed.drop('satisfaction', axis=1)
y_test = test_processed['satisfaction']
```

Ο παραπάνω κώδικας διαχωρίζει το **εκπαιδευτικό** και το **δοκιμαστικό σύνολο δεδομένων** σε δύο μέρη, χρησιμοποιώντας τη μέθοδο `drop()` για να αφαιρέσει τη στήλη `'satisfaction'` από το εκπαιδευτικό και το δοκιμαστικό σύνολο δεδομένων, ώστε να μείνουν μόνο τα χαρακτηριστικά για την εκπαίδευση του μοντέλου, ενώ η στήλη `'satisfaction'` απομονώνεται ως στόχος για να γίνει η πρόβλεψη.

1. **Χαρακτηριστικά (Features)**: Είναι οι στήλες που θα χρησιμοποιηθούν για την εκπαίδευση του μοντέλου.
2. **Στόχος (Target)**: Είναι η στήλη που θέλουμε να προβλέψουμε (στην περίπτωση αυτή, η "ικανοποίηση" του πελάτη, δηλαδή η στήλη `'satisfaction'`).

```{python}
# Εξαγωγή μοναδικών ετικετών των κλάσεων από το σύνολο δεδομένων
# Bρίσκει τις μοναδικές κατηγορίες από την μεταβλητή στόχο και τις αποθηκεύει στη μεταβλητή `class_labels`.
y = y_train.map({0: 'neutral or dissatisfied', 1: 'satisfied'})
class_labels = y.unique() 

y_all = np.concatenate((y_train, y_test))
```

Ο παραπάνω κώδικας εκτελεί τα εξής βήματα:

1. **Αντικατάσταση αριθμητικών ετικετών με κατηγορίες κλάσεων**:  
   - Η μέθοδος **`map()`** μετατρέπει τις ετικέτες στόχου στο `y_train`:
     - `0` → `'neutral or dissatisfied'`
     - `1` → `'satisfied'`
   - Αποθηκεύει τις μετατραπείσες ετικέτες στη μεταβλητή `y`.

2. **Εξαγωγή μοναδικών κατηγοριών κλάσεων**:
   - Το αποτέλεσμα είναι: `['neutral or dissatisfied', 'satisfied']`.

3. **Συνένωση ετικετών εκπαίδευσης και δοκιμής**:  
   - Η συνάρτηση **`np.concatenate()`** συνενώνει τα δεδομένα `y_train` και `y_test` σε έναν ενιαίο πίνακα `y_all`, που περιέχει όλες τις ετικέτες στόχου από το σύνολο εκπαίδευσης και δοκιμής.

```{python}
# Κλιμάκωση των χαρακτηριστικών
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_all_scaled = np.vstack((X_train_scaled, X_test_scaled))
```

Ο παραπάνω κώδικας πραγματοποιεί **κλιμάκωση των χαρακτηριστικών** και συνδυάζει τα κλιμακωμένα δεδομένα εκπαίδευσης και δοκιμής σε ένα ενιαίο σύνολο. Αναλυτικά:

1. **Δημιουργία αντικειμένου `StandardScaler`.**
2. **Κλιμάκωση δεδομένων εκπαίδευσης.**
3. **Κλιμάκωση δεδομένων δοκιμής.**
4. **Συνένωση των κλιμακωμένων δεδομένων.**

### **Ανάλυση Κύριων Συνιστωσών (PCA)**

```{python}
# Δημιουργία και εφαρμογή PCA
pca = PCA(n_components=2) # Δημιουργεί PCA μοντέλο με 2 συνιστώσες.
# Εφαρμόζει PCA στα δεδομένα εκπαίδευσης, δοκιμής και στο σύνολο των δεδομένων.
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)
X_pca = pca.transform(X_all_scaled)

# Υπολογισμός της εξηγούμενης διακύμανσης
explained_variance_ratio = pca.explained_variance_ratio_ # Υπολογίζει πόση διακύμανση εξηγεί κάθε κύρια συνιστώσα.
cumulative_variance_ratio = np.cumsum(explained_variance_ratio) # Υπολογίζει την αθροιστική εξηγούμενη διακύμανση.

# Δημιουργία γραφήματος
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8), sharey=True)
# Δημιουργεί δύο γραφήματα διασποράς
# Αριστερό Γράφημα: Σύγκριση δεδομένων εκπαίδευσης και δοκιμής.
plt.subplot(1, 2, 1)
for i, target_name in enumerate(class_labels):
    mask_train = y_train == i
    mask_test = y_test == i
    
    plt.scatter(
        X_train_pca[mask_train, 0], 
        X_train_pca[mask_train, 1],
        label=f"Εκπαίδευση - {target_name}"
    )
    plt.scatter(
        X_test_pca[mask_test, 0], 
        X_test_pca[mask_test, 1], 
        label=f"Δοκιμή - {target_name}", 
        marker='x'
    )

plt.xlabel(f"PC1 ({pca.explained_variance_ratio_[0]:.2%})")
plt.ylabel(f"PC2 ({pca.explained_variance_ratio_[1]:.2%})")
plt.legend()
plt.title("PCA - Train vs Test")

# Δεξί Γράφημα: Απεικόνιση όλων των δεδομένων μαζί.
plt.subplot(1, 2, 2)
for i, target_name in enumerate(class_labels):
    mask = y_all == i
    plt.scatter(
        X_pca[mask, 0], 
        X_pca[mask, 1], 
        label=f"{target_name}",
        alpha=0.3,  # Προσθήκη διαφάνειας
        s=20       # Μικρότερο μέγεθος σημείων
    )
# Προσθέτει ετικέτες αξόνων με τα ποσοστά εξηγούμενης διακύμανσης.
plt.xlabel(f"PC1 ({pca.explained_variance_ratio_[0]:.2%})")
plt.legend()
plt.title("PCA - Όλα τα δεδομένα")

plt.tight_layout()
plt.show()

# Εκτύπωση της εξηγούμενης διακύμανσης
# Εμφανίζει το ποσοστό διακύμανσης που εξηγεί κάθε συνιστώσα.
print("\nΕξηγούμενη διακύμανση ανά component:")
for i, var in enumerate(explained_variance_ratio):
    print(f"PC{i+1}: {var:.2%}")
# Εμφανίζει τη συνολική εξηγούμενη διακύμανση από τις δύο πρώτες συνιστώσες.
print(f"\nΣυνολική εξηγούμενη διακύμανση από τα 2 πρώτα components: {sum(explained_variance_ratio[:2]):.2%}")
```

Ο παραπάνω κώδικας εκτελεί ***Ανάλυση Κύριων Συνιστωσών*** *(PCA)* και οπτικοποιεί τα αποτελέσματα. Συγκεκριμένα:

1. **Εφαρμογή PCA**:
   - Μειώνει τις διαστάσεις των δεδομένων σε 2D για οπτικοποίηση.
2. **Υπολογισμός Διακύμανσης.**
3. **Δημιουργία Γραφημάτων.**
4. **Εκτύπωση Αποτελεσμάτων.**

```{python}
# Δημιουργία ενός μεγάλου σχήματος διαστάσεων (15x6).
plt.figure(figsize=(15, 6))

# Δημιουργία του γραφήματος
# Για κάθε κλάση (`class_labels`), σχεδιάζει:    
for i, target_name in enumerate(class_labels):
    mask_train = y_train == i
    mask_test = y_test == i
    # Τα δεδομένα εκπαίδευσης με κανονικούς δείκτες.
    plt.scatter(
        X_train_pca[mask_train, 0], 
        X_train_pca[mask_train, 1],
        label=f"Εκπαίδευση - {target_name}" 
    )
    # Τα δεδομένα δοκιμής με δείκτες `x`.
    plt.scatter(
        X_test_pca[mask_test, 0], 
        X_test_pca[mask_test, 1], 
        label=f"Δοκιμή - {target_name}", 
        marker='x'
    )

plt.xlabel("First Principal Component")
plt.ylabel("Second Principal Component")
plt.legend()
plt.title("Κατανομή δεδομένων (εκπαίδευση & δοκιμή)")
plt.show()
```

Στόχος του παραπάνω κώδικα είναι να συγκριθεί η κατανομή των δεδομένων εκπαίδευσης και δοκιμής σε έναν δισδιάστατο χώρο:

1. **Δημιουργεί ένα μεγάλο γράφημα.**
2. **Οπτικοποιεί τα δεδομένα εκπαίδευσης και δοκιμής.**
3. **Προσθέτει ετικέτες άξονων, υπόμνημα και τίτλο.**


## **Πρόβλεψη**

## **1. Gaussian Naive Bayes (GNB)**

```{python}
# Δημιουργία και εκπαίδευση του κατηγοριοποιητή Gaussian Naive Bayes 
gnb = GaussianNB()
gnb.fit(X_train_scaled, y_train)
```

Ο παραπάνω κώδικας εκπαιδεύει το μοντέλο **Gaussian Naive Bayes** χρησιμοποιώντας τα κλιμακωμένα δεδομένα εκπαίδευσης και τις ετικέτες στόχου, ώστε το μοντέλο να μπορεί να κάνει προβλέψεις για νέα δεδομένα:

1. **Δημιουργία του κατηγοριοποιητή `Gaussian Naive Bayes`.**
2. **Εκπαίδευση του μοντέλου.**

```{python}
# Προβλέψεις
y_pred = gnb.predict(X_test_scaled)
```

Ο παραπάνω κώδικας χρησιμοποιεί το εκπαιδευμένο μοντέλο για να κάνει προβλέψεις στις κλιμακωμένες τιμές των δεδομένων δοκιμής και αποθηκεύει τα αποτελέσματα:

1. **Προβλέπει τις ετικέτες για τα δεδομένα δοκιμής.**
2. **Αποθηκεύει τις προβλέψεις.**

```{python}
# Δοκιμή με νέα παρατήρηση
# Δημιουργία τυχαίου δείγματος με τιμές από το εύρος τιμών των χαρακτηριστικών
np.random.seed(25)  # Ορισμός seed για αναπαραγωγιμότητα
feature_min = X_train.min(axis=0)  # Ελάχιστες τιμές ανά χαρακτηριστικό
feature_max = X_train.max(axis=0)  # Μέγιστες τιμές ανά χαρακτηριστικό
random_sample = np.random.uniform(feature_min, feature_max, size=(1, X_train.shape[1]))
random_sample_scaled = scaler.transform(random_sample)
random_sample_pca = pca.transform(random_sample_scaled) # Μετατρέπει το δείγμα στο χώρο PCA
predicted_class = gnb.predict(random_sample) # Χρησιμοποιεί το μοντέλο Naive Bayes για πρόβλεψη

# Αντιστοιχίζει την αριθμητική πρόβλεψη σε ένα ερμηνεύσιμο string label.
predicted_class_label = class_labels[predicted_class[0]]

print(f"\n\tΗ πρόβλεψη για το νέο δείγμα: {predicted_class_label}\n") #Εμφανίζει την πρόβλεψη στην οθόνη

# Δημιουργία του figure και των subplots
fig, ax = plt.subplots(figsize=(12, 8))

# Scatter plot για τα δεδομένα εκπαίδευσης και δοκιμής
for i, target_name in enumerate(class_labels):
    mask_train = y_train == i
    mask_test = y_test == i
    
    ax.scatter(
        X_train_pca[mask_train, 0], 
        X_train_pca[mask_train, 1],
        label=f"Εκπαίδευση - {target_name}",
        alpha=0.6
    )
    ax.scatter(
        X_test_pca[mask_test, 0], 
        X_test_pca[mask_test, 1], 
        label=f"Δοκιμή - {target_name}", 
        marker='x',
        alpha=0.6
    )

# Προσθήκη του νέου δείγματος ως κόκκινο σημείο
ax.scatter(random_sample_pca[0, 0], random_sample_pca[0, 1], color='red', label="Νέο Δείγμα", marker='o', s=100)
# Προσθήκη βέλους που δείχνει το νέο δείγμα
ax.annotate(
    '**Νέο Δείγμα**', 
    xy=(random_sample_pca[0, 0], random_sample_pca[0, 1]), 
    xytext=(random_sample_pca[0, 0] + 1, random_sample_pca[0, 1] + 1),
    arrowprops=dict(facecolor='black', shrink=0.05),
    fontsize=18, fontweight='bold'
)

# Προσθήκη ετικετών αξόνων, τίτλου και υπομνήματος
ax.set_xlabel("First Principal Component")
ax.set_ylabel("Second Principal Component")
ax.legend()
ax.set_title("Θέση του νέου δείγματος σε σχέση με τα δεδομένα")

# Ρύθμιση της διάταξης και εμφάνιση του γραφήματος
plt.tight_layout()
plt.show()
```

Ο παραπάνω κώδικας εκτελεί μια πρόβλεψη για ένα νέο δείγμα και το οπτικοποιεί. Συγκεκριμένα:

1. **Δημιουργία και Πρόβλεψη Νέου Τυχαίου Δείγματος.**
2. **Δημιουργία Γραφήματος.**
3. **Μορφοποίηση.**

```{python}
# Εκτίμιση και αξιολόγηση του μοντέλου
accuracy_gnb = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy_gnb:.2f}")

roc_auc_gnb = roc_auc_score(y_test, y_pred)
print(f"ROC_AUC: {roc_auc_gnb:.2f}")

# Εκτύπωση αναλυτικής αναφοράς ταξινόμησης
print("\n\tClassification Report:")
print(classification_report(y_test, y_pred))

# Οπτικοποίηση 1: Μήτρα σύγχυσης
conf_matrix = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)
disp.plot(cmap='magma')
plt.title("Μήτρα Σύγχυσης")
plt.show()
```

Ο παραπάνω κώδικας εκτιμά και αξιολογεί την απόδοση του εκπαιδευμένου μοντέλου **Gaussian Naive Bayes** χρησιμοποιώντας διάφορους δείκτες και μετρικές:

1. **Υπολογισμός της ακρίβειας (Accuracy).**
2. **Υπολογισμός του δείκτη ROC AUC.**
3. **Εκτύπωση αναφοράς ταξινόμησης.**
   - **`classification_report(y_test, y_pred)`**: Εκτυπώνει μια αναλυτική αναφορά για την απόδοση του μοντέλου, η οποία περιλαμβάνει:
     - **Precision**: Την ακρίβεια του μοντέλου για κάθε κατηγορία.
     - **Recall**: Την αναλογία των πραγματικών θετικών περιπτώσεων που ανιχνεύθηκαν σωστά.
     - **F1-Score**: Τον αρμονικό μέσο όρο της ακρίβειας και της ανάκλησης.
     - **Support**: Τον αριθμό των παρατηρήσεων για κάθε κατηγορία.
4. **Οπτικοποίηση της μήτρας σύγχυσης.**

```{python}
# Αξιολόγηση της σημασίας των χαρακτηριστικών στην πρόβλεψη
# Χρησιμοποιώντας την μέση διακύμανση κάθε χαρακτηριστικού για κάθε κλάση
feature_importance = pd.DataFrame({
    'Feature': X_train.columns,
    'Mean Variance': np.mean(gnb.var_, axis=0)
})
feature_importance = feature_importance.sort_values('Mean Variance', ascending=True)

print("\nΣημασία χαρακτηριστικού βάση της μέσης διακύμανσης:")
print(feature_importance)
```

Ο παραπάνω κώδικας αξιοποιεί τη **διακύμανση (*variance*)** των χαρακτηριστικών για κάθε κατηγορία ώστε να εκτιμήσει τη σημασία τους στη διαδικασία κατηγοριοποίησης. Ας αναλύσουμε πώς καταλαβαίνουμε τη σημασία ενός χαρακτηριστικού με βάση τη διακύμανση:

#### **Τι σημαίνει η διακύμανση *(**variance**)* σε αυτή την περίπτωση;**

Στο πλαίσιο του **Gaussian Naive Bayes (GNB)**, υποθέτουμε ότι κάθε χαρακτηριστικό ακολουθεί μια κανονική κατανομή (**Gaussian distribution**) για κάθε κατηγορία. Η διακύμανση (**var_**) είναι μια μέτρηση της διασποράς των τιμών ενός χαρακτηριστικού σε κάθε κατηγορία.

1. **Χαμηλή Διακύμανση**:
   - Ένα χαρακτηριστικό με χαμηλή διακύμανση είναι πιο **σταθερό** μέσα σε κάθε κατηγορία. Αυτό σημαίνει ότι οι τιμές του δεν αλλάζουν πολύ από δείγμα σε δείγμα εντός της ίδιας κατηγορίας, καθιστώντας το πιο **διακριτικό** για την κατηγοριοποίηση.

2. **Υψηλή Διακύμανση**:
   - Ένα χαρακτηριστικό με υψηλή διακύμανση έχει μεγαλύτερη διασπορά μέσα σε κάθε κατηγορία. Ενδέχεται να είναι λιγότερο χρήσιμο για τη διάκριση των κατηγοριών, επειδή οι τιμές του μπορεί να επικαλύπτονται σημαντικά μεταξύ κατηγοριών.

#### **Πώς αξιολογούμε τη σημασία των χαρακτηριστικών;**

**1. Χαρακτηριστικά με υψηλή διακύμανση:** 

   - (**Class, Online boarding, Inflight entertainment, Seat comfort, On-board service, Cleanliness, Leg room service, Baggage handling, Inflight service, Checkin service, Food and drink, Age, Flight Distance, Inflight wifi service, Departure Delay in Minutes, Arrival Delay in Minutes, Gender, Departure/Arrival time convenient, Ease of Online booking, Gate location**)

   - Μπορεί να μην είναι πολύ χρήσιμα, καθώς η μεγάλη διασπορά υποδηλώνει ότι οι τιμές τους επικαλύπτονται μεταξύ των κατηγοριών.
   - Πιθανόν να προκαλούν θόρυβο στο μοντέλο.

**2. Χαρακτηριστικά με χαμηλή διακύμανση:** 
   - Είναι πιο σημαντικά για την κατηγοριοποίηση, καθώς διαχωρίζουν καλύτερα τις κατηγορίες.
   - Αυτά τα χαρακτηριστικά συμβάλλουν περισσότερο στην ακρίβεια του μοντέλου.

Σύμφωνα με τα αποτελέσματα της ανάλυσης τα 2 χαρακτηριστικά που προέκυψαν είναι:
- **Customer Type:** Οι τακτικοί πελάτες μπορεί να έχουν υψηλότερες προσδοκίες, επηρεάζοντας την αντίληψή τους για την υπηρεσία.
- **Type of Travel:** Οι επαγγελματίες ταξιδιώτες μπορεί να δίνουν μεγαλύτερη έμφαση στην ακρίβεια και την άνεση.

## **2. Λογιστική Παλινδρόμηση - Logistic Regression**

```{python}
# Δημηιουργία και εκπαίδευση του μοντέλου Λογιστικής Παλλινδρόμησης
logreg = LogisticRegression()
logreg.fit(X_train_scaled, y_train)
```

Ο παραπάνω κώδικας εκπαιδεύει το μοντέλο **Λογιστικής Παλινδρόμησης** για να προβλέψει την κατηγορία (π.χ., ικανοποίηση ή μη) με βάση τα κλιμακωμένα χαρακτηριστικά του συνόλου εκπαίδευσης:

1. **Δημιουργία του μοντέλου Λογιστικής Παλινδρόμησης.**
2. **Εκπαίδευση του μοντέλου.**

```{python}
# Προβλέψεις
y_pred = logreg.predict(X_test_scaled)
```

Ο παραπάνω κώδικας χρησιμοποιεί το εκπαιδευμένο μοντέλο για να προβλέψει αν ο πελάτης είναι ικανοποιημένος ή μη ικανοποιημένος με βάση τα κλιμακωμένα δεδομένα του δοκιμαστικού συνόλου (`X_test_scaled`):

1. **Προβλέπει τις ετικέτες για τα δεδομένα δοκιμής.**
2. **Αποθηκεύει τις προβλέψεις.**

```{python}
# Εκτίμιση και αξιολόγηση του μοντέλου
accuracy_logreg = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy_logreg:.2f}")

roc_auc_logreg = roc_auc_score(y_test, y_pred)
print(f"ROC_AUC: {roc_auc_logreg:.2f}")

# Εκτύπωση αναλυτικής αναφοράς ταξινόμησης
print("\n\tClassification Report:")
print(classification_report(y_test, y_pred))

# Οπτικοποίηση 1: Μήτρα σύγχυσης
conf_matrix = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)
disp.plot(cmap='magma')
plt.title("Μήτρα Σύγχυσης")
plt.show()
```

Ο παραπάνω κώδικας εκτελεί τα εξής βήματα για την εκτίμηση και αξιολόγηση του μοντέλου της **Λογιστικής Παλινδρόμησης**:

1. **Υπολογισμός της ακρίβειας (accuracy).**
2. **Υπολογισμός του δείκτη ROC AUC.**
3. **Εκτύπωση αναλυτικής αναφοράς ταξινόμησης.**
4. **Οπτικοποίηση της μήτρας σύγχυσης (Confusion Matrix).**

```{python}
# Δοκιμή με νέα παρατήρηση
new_sample = np.zeros((1, X_train.shape[1]))
new_sample_scaled = StandardScaler().fit_transform(new_sample)
predicted_class = logreg.predict(new_sample_scaled)
new_sample_pca = pca.transform(new_sample_scaled)

# Map the predicted class to the corresponding string label
predicted_class_label = class_labels[predicted_class[0]]

print(f"\n\tΗ πρόβλεψη για το νέο δείγμα: {predicted_class_label}\n")
```

Ο παραπάνω κώδικας εισάγει ένα νέο δείγμα, το μετασχηματίζει, προβλέπει την κλάση του και το μετατρέπει με PCA. Συγκεκριμένα:

1. **Δημιουργία Νέου Δείγματος**: Δημιουργεί ένα δείγμα με μηδενικές τιμές.
2. **Κανονικοποίηση**: Εφαρμόζει StandardScaler για να κλιμακώσει το δείγμα.
3. **Πρόβλεψη Κλάσης**: Χρησιμοποιεί το μοντέλο λογιστικής παλινδρόμησης για πρόβλεψη.
4. **Μετασχηματισμός PCA**: Μετατρέπει το δείγμα στο χώρο των κύριων συνιστωσών.
5. **Εκτύπωση Αποτελέσματος**: Εμφανίζει την προβλεπόμενη κλάση του δείγματος.

```{python}
# Αξιολόγηση της σημασίας των χαρακτηριστικών στην πρόβλεψη
# Χρησιμοποιώντας τους συντελεστές του μοντέλου
# Λήψη συντελεστών του μοντέλου
coefficients = logreg.coef_[0]
feature_importance = pd.DataFrame({
    'Feature': X_train.columns,
    'Coefficient': coefficients
}).sort_values('Coefficient', ascending=False)

print("Σημασία Χαρακτηριστικών (Βάσει Συντελεστών):")
print(feature_importance)
```

Ο παραπάνω κώδικας υπολογίζει τη σημασία των χαρακτηριστικών χρησιμοποιώντας τους συντελεστές του μοντέλου λογιστικής παλινδρόμησης και δημιουργεί έναν πίνακα που ταξινομεί τα χαρακτηριστικά σύμφωνα με την επίδρασή τους στην πρόβλεψη, προσδιορίζοντας ποια χαρακτηριστικά έχουν τη μεγαλύτερη ή μικρότερη επίδραση στην κατηγοριοποίηση:

1. **Λήψη των συντελεστών του μοντέλου.**
2. **Δημιουργία πίνακα με τη σημασία των χαρακτηριστικών.**
3. **Εκτύπωση της σημασίας των χαρακτηριστικών.**

Για να ερμηνεύσουμε τα αποτελέσματα του κώδικα και να εντοπίσουμε τα σημαντικά και λιγότερο σημαντικά χαρακτηριστικά, πρέπει να κοιτάξουμε τους συντελεστές του μοντέλου λογιστικής παλινδρόμησης. Τα χαρακτηριστικά με τους *μεγαλύτερους* συντελεστές *(θετικούς ή αρνητικούς)* είναι τα *πιο σημαντικά* για την πρόβλεψη. Αυτά επηρεάζουν περισσότερο την κατηγοριοποίηση, ενώ τα χαρακτηριστικά με *μικρούς ή μηδενικούς* συντελεστές έχουν *λιγότερη ή καθόλου επίδραση* στην πρόβλεψη.

### **1. Σημασία των χαρακτηριστικών**:
Ο πίνακας `feature_importance` που δημιουργείται περιλαμβάνει τα χαρακτηριστικά και τους αντίστοιχους συντελεστές τους. Οι συντελεστές αυτοί δείχνουν πόσο **σχετικό** είναι το κάθε χαρακτηριστικό για την πρόβλεψη της κατηγορίας στόχου.

### **2. Ερμηνεία των συντελεστών**:
- **Θετικοί συντελεστές**: Όταν ο συντελεστής ενός χαρακτηριστικού είναι θετικός, αυτό σημαίνει ότι καθώς η τιμή του χαρακτηριστικού αυξάνεται, η πιθανότητα να ανήκει το δείγμα στην κατηγορία "ικανοποιημένος" (ή "1") αυξάνεται.
- **Αρνητικοί συντελεστές**: Αν ο συντελεστής είναι αρνητικός, τότε καθώς η τιμή του χαρακτηριστικού αυξάνεται, η πιθανότητα να ανήκει το δείγμα στην κατηγορία "ικανοποιημένος" μειώνεται.
- **Μηδενικοί ή μικροί συντελεστές**: Αν ένας συντελεστής είναι κοντά στο μηδέν ή πολύ μικρός, αυτό σημαίνει ότι το χαρακτηριστικό δεν έχει ισχυρή επίδραση στην πρόβλεψη της κατηγορίας.

### **3. Τα πιο σημαντικά χαρακτηριστικά**:
- **Τα χαρακτηριστικά με τους μεγαλύτερους (θετικούς ή αρνητικούς) συντελεστές** είναι τα πιο σημαντικά. Αυτά έχουν την **μεγαλύτερη επίδραση** στην απόφαση του μοντέλου για την κατηγορία του πελάτη (ικανοποιημένος ή μη).
- Αντίστοιχα, αν ο συντελεστής είναι **αρνητικός και μεγάλος**, σημαίνει ότι το χαρακτηριστικό μειώνει την πιθανότητα να είναι ικανοποιημένος ο πελάτης.
- **Σημαντικά χαρακτηριστικά**:
  - `Type of Travel` (θετικός συντελεστής 1.269038): Η πρόβλεψη για την ολική ικανοποίηση του πελάτη επηρεάζεται πάρα πολύ από τον σκοπό για τον οποίο ταξιδεύει ο εν λόγω πελάτης.
  - `Online boarding` (θετικός συντελεστής 0.832768): Το επίπεδο ικανοποίησης από την online επιβίβαση του κάθε πελάτη, έχει αρκετή σημασία στην πρόβλεψη της ολικής ικανοποίησης του.
  - `Customer Type` (θετικός συντελεστής 0.772970): Η συχνότητα επιλογής της εταιρίας από τον κάθε πελάτη, δηλαδή αν ο πελάτης είναι συχνός ή μη ταξιδιώτης της εταιρίας, επηρεάζει σημαντικά την πρόβλεψη.

### **4. Τα λιγότερο σημαντικά χαρακτηριστικά**:
- **Τα χαρακτηριστικά με μικρούς ή μηδενικούς συντελεστές** έχουν λιγότερη ή καθόλου επίδραση στην απόφαση του μοντέλου. Αυτό σημαίνει ότι δεν συμβάλλουν σημαντικά στην πρόβλεψη της ικανοποίησης ή δυσαρέσκειας του πελάτη.

- **Λιγότερο σημαντικά χαρακτηριστικά**:
  - `Arrival Delay in Minutes` (αρνητικός συντελεστής -0.342616): Η χρονική διάρκεια της καθυστέρησης κατά την άφιξη του αεροπλάνου στον προορισμό, έχει αρκετή σημασία στην πρόβλεψη. Όσο η τιμή αυτή αυξάνεται, τόσο πιθανότερη είναι η δυσαρέσκεια του πελάτη.
  - `Departure/Arrival time convenient` (αρνητικός μικρός συντελεστής -0.192377): Παρ' όλη την μικρή αρνητική τιμή, το επίπεδο ικανοποίησης του πελάτη από τις ώρες αναχώρησης και άφιξης, δηλαδή κατά πόσο βολικές ήταν για αυτόν, έχει έναν σημαντικό ρόλο στην ολική ικανοποίησή του.
  - `Ease of Online booking` (αρνητικός μικρός συντελεστής -0.192183): Το πόσο φάνηκε εύκολη η online κράτηση σε κάποιον πελάτη, επηρεάζει την ολική ικανοποίησή του από την εταιρία.

```{python}
auc_scores = [accuracy_gnb, roc_auc_gnb, accuracy_logreg, roc_auc_logreg]
model_scores = pd.DataFrame(auc_scores, index=['Accuracy score Gaussian Naive Bayes','ROC-AUC score Gaussian Naive Bayes', 'Accuracy score Logistic Regression', 'ROC-AUC score Logistic Regression'], columns=['Scores'])
model_scores
```

Ο παραπάνω κώδικας συγκεντρώνει και παρουσιάζει τις μετρικές απόδοσης για τα μοντέλα Gaussian Naive Bayes και Logistic Regression σε έναν πίνακα, προκειμένου να γίνει μια ευκολότερη σύγκριση των αποτελεσμάτων:

1. **Δημιουργεί μια λίστα `auc_scores`**:
   - Η λίστα περιέχει τέσσερις τιμές, οι οποίες αντιστοιχούν σε **μετρικές απόδοσης** για δύο μοντέλα:
     - `accuracy_gnb`: Η ακρίβεια του μοντέλου **Gaussian Naive Bayes**.
     - `roc_auc_gnb`: Η τιμή του **ROC-AUC** για το μοντέλο **Gaussian Naive Bayes**.
     - `accuracy_logreg`: Η ακρίβεια του μοντέλου **Logistic Regression**.
     - `roc_auc_logreg`: Η τιμή του **ROC-AUC** για το μοντέλο **Logistic Regression**.

2. **Δημιουργεί ένα `DataFrame` με τις τιμές της λίστας**:
   - Χρησιμοποιεί τη βιβλιοθήκη **`pandas`** για να δημιουργήσει έναν πίνακα (DataFrame) με τις μετρικές απόδοσης.
   - Ο πίνακας έχει δύο στήλες:
     - **`Scores`**: Περιέχει τις τιμές των μετρικών απόδοσης (όπως ακρίβεια και ROC-AUC).
     - **`index`**: Περιέχει τις ετικέτες για κάθε σειρά, οι οποίες αναφέρουν ποιο μοντέλο και ποια μέτρηση (accuracy ή ROC-AUC) αφορά.

3. **Εμφανίζει τον πίνακα `model_scores`**:
   - Ο πίνακας εμφανίζει τις τιμές των μετρικών απόδοσης για τα δύο μοντέλα, διευκολύνοντας τη σύγκριση της απόδοσης τους.

Τα αποτελέσματα του πίνακα δείχνουν τις επιδόσεις δύο μοντέλων **Gaussian Naive Bayes** και **Logistic Regression** με βάση δύο σημαντικές μετρικές απόδοσης: **Accuracy** και **ROC-AUC**.

Ας εξηγήσουμε κάθε μετρική:

### **1. Accuracy score (Ακρίβεια)**

Η **ακρίβεια** είναι η αναλογία των σωστών προβλέψεων προς το σύνολο των παρατηρήσεων:

![alt text](image.png)

#### Αποτελέσματα:
- **Gaussian Naive Bayes**: 0.861949 (86.19%)
  - Το μοντέλο **Gaussian Naive Bayes** προβλέπει σωστά το 86.19% των περιπτώσεων.
  
- **Logistic Regression**: 0.871343 (87.13%)
  - Το μοντέλο **Logistic Regression** έχει ελαφρώς καλύτερη ακρίβεια, με 87.13%.

### **2. ROC-AUC score (Area Under the ROC Curve)**

Η **ROC-AUC** μετρική αξιολογεί την ικανότητα του μοντέλου να διαχωρίσει σωστά τις κατηγορίες (σε αυτήν την περίπτωση, "ικανοποιημένος" και "μη ικανοποιημένος").
- Η **ROC-AUC** κυμαίνεται από 0 μέχρι 1, με τιμές κοντά στο 1 να υποδεικνύουν εξαιρετική απόδοση και τιμές κοντά στο 0.5 να δείχνουν τυχαία πρόβλεψη.
  
#### Αποτελέσματα:
- **Gaussian Naive Bayes**: 0.857421 (85.74%)
  - Το **Gaussian Naive Bayes** έχει μια **ROC-AUC** τιμή της 85.74%, υποδεικνύοντας ότι έχει καλή απόδοση στη διάκριση μεταξύ των κατηγοριών.
  
- **Logistic Regression**: 0.867242 (86.72%)
  - Το **Logistic Regression** έχει μια ελαφρώς καλύτερη **ROC-AUC** τιμή (86.72%), πράγμα που σημαίνει ότι έχει λίγο καλύτερη ικανότητα διάκρισης των κατηγοριών από το **Gaussian Naive Bayes**.

### **Συνολική Σύγκριση:**

- Και τα δύο μοντέλα έχουν εξαιρετική απόδοση, με **Logistic Regression** να υπερέχει ελαφρώς σε τόσο την ακρίβεια όσο και στην **ROC-AUC**.
- **Gaussian Naive Bayes** προσφέρει επίσης πολύ καλή απόδοση, με μικρές διαφορές σε σχέση με το **Logistic Regression**.

Τα αποτελέσματα δείχνουν ότι τα δύο μοντέλα έχουν **παρόμοια απόδοση**, με το **Logistic Regression** να είναι λίγο πιο ακριβές και να διαχωρίζει καλύτερα τις κατηγορίες, σύμφωνα με την **ROC-AUC** μετρική. Ωστόσο, η διαφορά είναι μικρή, και το **Gaussian Naive Bayes** παραμένει μια πολύ καλή επιλογή για αυτό το πρόβλημα.

## **Συμπέρασμα**
Σύμφωνα με τα τελικά αποτελέσματα της εκτίμησης των 2 μοντέλων, η **Λογιστική Παλινδρομηση** υπερείχε ελάχιστα του **Gaussian Naive Bayes** κατηγοριοποιητή στις προβλέψεις. Θετικό αποτέλεσμα αποτελεί η εύρεση των 2 μεταβλητών/χαρακτηριστικών που επηρεάζουν την συνολική ικανοποίηση των πελατών/ταξιδιωτών της αεροπορικής κι αυτά είναι: ο όρος του ταξιδιού, προσωπικό ταξίδι ή επαγγελματικό ταξίδι και αν ο πελάτης είναι τακτικός ταξιδιώτης ή μη-τακτικός ταξιδιώτης της αεροπορικής εταιρίας.

